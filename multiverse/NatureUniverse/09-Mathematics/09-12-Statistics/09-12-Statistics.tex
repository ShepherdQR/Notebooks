%%============
%%  ** Author: Shepherd Qirong
%%  ** Date: 2022-05-06 20:36:41
%%  ** Github: https://github.com/ShepherdQR
%%  ** LastEditors: Shepherd Qirong
%%  ** LastEditTime: 2022-06-05 23:08:13
%%  ** Copyright (c) 2019--20xx Shepherd Qirong. All rights reserved.
%%============

\documentclass[UTF8]{../09-Mathematics}
\begin{document}

\title{09-12-Statistics}
\date{Created on 20220605.\\   Last modified on \today.}
\maketitle
\tableofcontents


\chapter{Introduction}



数理统计学
a: 抽样理论(包括抽样分布、抽样调查等), 
b: 假设检验, 
c: 非参数统计, 
d: 方差分析, 
e: 相关回归分析, 
f: 统计推断, 
g: 贝叶斯统计（包括参数估计等）, 
h: 试验设计, 
i: 多元分析, 
j: 统计判决理论, 
k: 时间序列分析, 
l: 数理统计学其他学科。

应用统计数学
a: 统计质量控制, b: 可靠性数学, c: 保险数学, d: 统计模拟。




\chapter{抽样理论}
抽样理论(包括抽样分布、抽样调查等)
\chapter{假设检验}
\chapter{非参数统计}
\chapter{方差分析}
\chapter{相关回归分析}
\chapter{统计推断}
\chapter{贝叶斯统计}
贝叶斯统计（包括参数估计等）
\chapter{试验设计}
\chapter{多元分析}
\chapter{统计判决理论}
\chapter{时间序列分析}
\chapter{数理统计学其他学科}

\chapter{统计质量控制}
\chapter{可靠性数学}
\chapter{保险数学}
\chapter{统计模拟}



\chapter{Information Throry}



香农第一定理（可变长无失真信源编码定理。霍夫曼编码也称为最佳编码, 由Huffman1952年提出, 压缩的极限是不同符号用不同的编码, 如果做到每个符号的代码长度等于它出现概率的对数, 则编码总长度就是信息熵。)
香农第二定理（有噪信道编码定理）
香农第三定理（保失真度准则下的有失真信源编码定理）

Shannon, 1948年10月, A Mathematical Theory of Communication, 提出信息熵: 

\begin{equation}
    H(X) = - \sum_i p_i logp_i
\end{equation}
提出比特单位。一段信息的信息量是固定的, 称为信息熵。无论怎么压缩, 信息熵是无失真信源编码的极限值
若编码的平均码长小于信息熵值, 必然发生差错（也就是有损）。


信道容量C计算公式: 
\begin{equation}
    C = B * log(1+ \frac{S}{N})
\end{equation}
B为信道带宽；S/N为信噪比, 通常用分贝（dB）表示。
噪声大, 信噪比接近0, C结果接近0。离路由器越远, 信噪比越小, 网速约下降。


\section{Models}
统计模型
\subsection{Fitts' Law}
Paul Fitts于1954年提出。是一个人机互动以及人体工程学中人类活动的模型。它预测了快速移动到目标区域所需的时间是目标区域的距离和目标区域大小的函数。费兹法则多用于表现指, 点动作的概念模型。无论是用手或手指进行接触, 或是在电脑屏幕上用假想的设备（例如, 鼠标）进行虚拟的触碰。

费兹法则可用多种不同公式表达, 比较普通用的是, 用一维的Shannon公式（Mackenzie,约克大学教授提出, 因其与香农定律相似而命名）: 
从一个起始位置移动到一个最终目标所需的时间由两个参数来决定, 到目标的距离和目标的大小（上图中的 D与 W）, 用数学公式表达为时间 T = a + b log2(D/W+1)。
T 是完成动作的时间
a代表装置开始结束的时间, b表示该装置的速度, 这些常数可从实测数据进行直线近似取得。
D是起始位置到目标中心的距离。
w是目标区域在运动维上的宽度。

\end{document}
